#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Apr 25 14:42:32 2024

@author: tungbioinfo
"""

import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
import tf_keras as tfk
import tensorflow_datasets as tfds
import tensorflow_probability as tfp


tfkl = tfk.layers
tfpl = tfp.layers
tfd = tfp.distributions

if tf.test.gpu_device_name() != '/device:GPU:0':
  print('WARNING: GPU device not found.')
else:
  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))
  
datasets, datasets_info = tfds.load(name="mnist", with_info=True, as_supervised=False)

def _preprocess(sample):
  image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.
  image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.
  return image, image

train_dataset = (datasets['train']
                 .map(_preprocess)
                 .batch(256)
                 .prefetch(tf.data.AUTOTUNE)
                 .shuffle(int(10e3)))
eval_dataset = (datasets['test']
                .map(_preprocess)
                .batch(256)
                .prefetch(tf.data.AUTOTUNE))

input_shape = datasets_info.features["image"].shape
encoded_size = 16
base_depth = 32

prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),
                        reinterpreted_batch_ndims=1)

encoder = tfk.Sequential([
    tfkl.InputLayer(input_shape=input_shape),
    tfkl.Lambda(lambda x: tf.cast(x, tf.float32) - 0.5),
    tfkl.Conv2D(base_depth, kernel_size=5, strides=1, padding="same", activation=tf.nn.leaky_relu),
    tfkl.Conv2D(base_depth, kernel_size=5, strides=2, padding="same", activation=tf.nn.leaky_relu),
    tfkl.Conv2D(2 * base_depth, kernel_size=5, strides=1, padding="same", activation=tf.nn.leaky_relu),
    tfkl.Conv2D(2 * base_depth, kernel_size=5, strides=2, padding="same", activation=tf.nn.leaky_relu),
    tfkl.Conv2D(4 * encoded_size, kernel_size=7, strides=1, padding="valid", activation=tf.nn.leaky_relu),
    tfkl.Flatten(),
    tfkl.Dense(tfpl.MultivariateNormalTriL.params_size(encoded_size),
               activation=None),
    tfpl.MultivariateNormalTriL(encoded_size, activity_regularizer=tfpl.KLDivergenceRegularizer(prior))])

decoder = tfk.Sequential([
    tfkl.InputLayer(input_shape=[encoded_size]),
    tfkl.Reshape([1, 1, encoded_size]),
    tfkl.Conv2DTranspose(2 * base_depth, kernel_size=7, strides=1, padding="valid", activation=tf.nn.leaky_relu),
    tfkl.Conv2DTranspose(2 * base_depth, kernel_size=5, strides=1, padding="same", activation=tf.nn.leaky_relu),
    tfkl.Conv2DTranspose(2 * base_depth, kernel_size=5, strides=2, padding="same", activation=tf.nn.leaky_relu),
    tfkl.Conv2DTranspose(base_depth, kernel_size=5, strides=1, padding="same", activation=tf.nn.leaky_relu),
    tfkl.Conv2DTranspose(base_depth, kernel_size=5, strides=2, padding="same", activation=tf.nn.leaky_relu),
    tfkl.Conv2DTranspose(base_depth, kernel_size=5, strides=1, padding="same", activation=tf.nn.leaky_relu),
    tfkl.Conv2D(filters=1, kernel_size=5, strides=1, padding="same", activation=None),
    tfkl.Flatten(),
    tfpl.IndependentBernoulli(input_shape, tfd.Bernoulli.logits)])

vae = tfk.Model(inputs=encoder.inputs, outputs=decoder(encoder.outputs[0]))

negloglik = lambda x, rv_x: -rv_x.log_prob(x)

vae.compile(optimizer=tfk.optimizers.Adam(learning_rate=1e-3), loss=negloglik)

_ = vae.fit(train_dataset, epochs=15, validation_data=eval_dataset)


x = next(iter(eval_dataset))[0][:10]
xhat = vae(x)

def display_imgs(x, y=None):
  if not isinstance(x, (np.ndarray, np.generic)):
    x = np.array(x)
  plt.ioff()
  n = x.shape[0]
  fig, axs = plt.subplots(1, n, figsize=(n, 1))
  if y is not None:
    fig.suptitle(np.argmax(y, axis=1))
  for i in range(n):
    axs.flat[i].imshow(x[i].squeeze(), interpolation='none', cmap='gray')
    axs.flat[i].axis('off')
  plt.show()
  plt.close()
  plt.ion()
    
display_imgs(x)
display_imgs(xhat.sample())
display_imgs(xhat.mode())




























































